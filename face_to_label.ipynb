{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "idens = torch.load(\"/mnt/rd/identity_df.pt\", map_location=\"cpu\")\n",
    "clip_embs = torch.load(\"/home/ubuntu/AutoLoRADiscovery/celeba_clip_arc_embeddings.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idens.columns \n",
    "# ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes',\n",
    "#        'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n",
    "#        'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n",
    "#        'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n",
    "#        'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
    "#        'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "#        'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair',\n",
    "#        'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n",
    "#        'Wearing_Necklace', 'Wearing_Necktie', 'Young', 'identity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset for training\n",
    "\n",
    "index_titles= ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes',\n",
    "       'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n",
    "       'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n",
    "       'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n",
    "       'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
    "       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair',\n",
    "       'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n",
    "       'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "\n",
    "\n",
    "\n",
    "class CelebaClipDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, idens, clip_embs, is_train=False):\n",
    "        self.clip_embs = clip_embs\n",
    "        self.idens = idens\n",
    "        n_idens = []\n",
    "        for i, index in enumerate(idens.index.values):\n",
    "            if index in clip_embs:\n",
    "                n_idens.append((i, index))\n",
    "        available_idens = n_idens\n",
    "        if is_train:\n",
    "            available_idens = available_idens[:int(len(available_idens) * 0.8)]\n",
    "        else:\n",
    "            available_idens = available_idens[int(len(available_idens) * 0.8):]\n",
    "        self.available_idens = available_idens\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.available_idens)\n",
    "    def __getitem__(self, idx):\n",
    "        idx, _idx = self.available_idens[idx]\n",
    "        return self.clip_embs[_idx][1], self.idens.iloc[idx].values[:-1].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CelebaClipDataset(idens, clip_embs, is_train=True)\n",
    "test_dataset = CelebaClipDataset(idens, clip_embs, is_train=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "print(\"train dataset size\", len(train_dataset))\n",
    "print(\"test dataset size\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "class CLiPToFeatures(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            # nn.LayerNorm(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            # nn.LayerNorm(256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 40),\n",
    "            nn.ReLU(),\n",
    "            # nn.LayerNorm(40),\n",
    "            nn.Linear(40, 40),\n",
    "\n",
    "            # nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLiPToFeatures().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test loop , with binary cross entropy loss\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for clip, iden in train_loader:\n",
    "        clip = clip.cuda().float()\n",
    "        # normalize clip\n",
    "        clip = clip / clip.norm(dim=-1, keepdim=True)\n",
    "        iden = iden.cuda().float() # is from -1 to 1, so we need to normalize it\n",
    "        iden = (iden + 1) / 2\n",
    "        optimizer.zero_grad()\n",
    "        out = model(clip)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, iden)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for clip, iden in test_loader:\n",
    "            clip = clip.cuda().float()\n",
    "            # normalize clip\n",
    "            clip = clip / clip.norm(dim=-1, keepdim=True)\n",
    "            iden = iden.cuda().float() # is from -1 to 1, so we need to normalize it\n",
    "            iden = (iden + 1) / 2\n",
    "            out = model(clip)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, iden)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            binary_class_pred = (out > 0)#.float()\n",
    "            binary_class_ground = (iden > 0.5)\n",
    "            total_correct += (binary_class_pred == binary_class_ground).sum().item()\n",
    "        \n",
    "\n",
    "        test_accuracy = total_correct / (len(test_loader.dataset)*40)\n",
    "        print(\"epoch\", epoch, \"test loss\", total_loss / len(test_loader), \" train loss\", train_loss / len(train_loader), \"test accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"/mnt/rd/clip_to_features.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at test dataset\n",
    "emb, iden = test_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_iden = model(emb.unsqueeze(0).cuda().float()).squeeze()#.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert logits to probabilities using sigmoid function\n",
    "probabilities = torch.sigmoid(pred_iden).cpu()\n",
    "\n",
    "# Binarize probabilities with a threshold of 0.5\n",
    "binary_predictions = (probabilities >= 0.5)#.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iden_binary = (torch.Tensor(iden) >= 0)#.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iden_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (binary_predictions == iden_binary).sum().item() / len(iden_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
